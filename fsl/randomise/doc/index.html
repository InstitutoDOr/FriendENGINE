<HTML><HEAD><link REL="stylesheet" TYPE="text/css" href="../fsl.css"><TITLE>FSL</TITLE></HEAD><BODY>
<TABLE BORDER=0 WIDTH="100%"><TR><TD ALIGN=CENTER><H1>Randomise v2.1</H1>
Permutation-based nonparametric inference<br><br>
<a href="#intro">intro</a> &nbsp;&nbsp;-&nbsp;&nbsp;
<a href="#using">using randomise</a> &nbsp;&nbsp;-&nbsp;&nbsp;
<a href="#examples">examples</a> &nbsp;&nbsp;-&nbsp;&nbsp;
<a href="#theory">theory</a> &nbsp;&nbsp;-&nbsp;&nbsp;
<a href="#refs">references</a>


<TD ALIGN=RIGHT><a href="../index.html"><IMG BORDER=0 SRC="../images/fsl-logo.jpg"></a></TR></TABLE><HR>

<a name="intro"></a><H2>INTRODUCTION</H2>

<p>Permutation methods (also known as randomisation methods) are used
for inference (thresholding) on statistic maps when the null
distribution is not known.  The null distribution is unknown because
either the noise in the data does not follow a simple distribution, or
because non-statandard statistics are used to summarize the data.

<b>randomise</b> is a simple permutation program enabling modelling
and inference using standard GLM design setup as used for example in
FEAT. It can output voxelwise and cluster-based tests, and also
offers variance smoothing as an option.  For more detail on
permutation testing in neuroimaging see Nichols and Holmes (2002).


<p><b>Test Statistics in Randomise</b>

<p><b>randomise</b> produces a test statistic image
(e.g., <code>ADvsNC_tstat1</code>, if your chosen output rootname
is <code>ADvsNC</code>) and sets of P-value images (stored as 1-P for
more convenient visualization, as bigger is then "better").  The table
below shows the filename suffices for each of the different test
statistics available.

<p>Voxel-wise uncorrected P-values are generally only useful when a
single voxel is selected <em>a priori</em> (i.e., you don't need to
worry about multiple comparisons across voxels).  The significance of
suprathreshold clusters (defined by the cluster-forming threshold) can
be assessed either by cluster size or cluster mass.  Size is just
cluster extent measured in voxels.  Mass is the sum of all statistic
values within the cluster.  Cluster mass has been reported to be more
sensitive than cluster size (Bullmore et al, 1999; Hayasaka &amp;
Nichols, 2003).


<p><b>Accounting for Repeated Measures</b>

<p>Permutation tests do not easily accommodate correlated datasets
  (e.g., temporally smooth timeseries), as null-hypothesis
  exchangeability is essential.  However, the case of "repeated
  measurements", or more than one measurement per subject in a
  multisubject analysis, can sometimes be accommodated.

<p><b>randomise</b> allows the definition of exchangeability blocks,
as specified by the <code>group_labels</code> option.  If specfied,
the program will only permute observations within block, i.e., only
observations with the same group label will be exchanged.  See
the <a href="#Ex:RepeatMeas">repeated measures example</a> below for
more detail.

<p><b>Confound Regressors</b>

<p>Unlike with the previous version of randomise, you no longer need
  to treat confound regressors in a special way (e.g. putting them in
  a separate design matrix). You can now include them in the main
  design matrix, and randomise will work out from your contrasts how
  to deal with them. For each contrast, an "effective regressor" is
  formed using the original full design matrix and the contrast, as
  well as a new set of "effective confound regressors", which are then
  pre-removed from the data before the permutation testing begins. One
  side-effect of the new, more powerful, approach is that the full set
  of permutations is run for each contrast separately, increasing the
  time that randomise takes to run.

<p><b>More information</b> on the theory behind randomise can be found
  in the <a href="#theory">Background Theory</a> section below.

<a name="using"></a><HR><H2>USING randomise</H2>

<p>A typical simple call to <b>randomise</b> uses the following
  syntax:

<p><code>randomise -i &lt;4D_input_data&gt; -o &lt;output_rootname&gt; -d design.mat -t
design.con -m &lt;mask_image&gt; -n 500 -D -T</code>

<p><code>design.mat</code> and <code>design.con</code> are text files
containing the design matrix and list of contrasts required; they
follow the same format as generated by FEAT (see below for
examples). The <code>-n 500</code> option tells randomise to generate
500 permutations of the data when building up the null distribution
to test against. The <code>-D</code> option tells randomise to demean
the data before continuing - this is necessary if you are not
modelling the mean in the design matrix. The <code>-T</code> option
tells randomise that the test statistic that you wish to use is TFCE
(threshold-free cluster enhancement - see below for more on this).

<p>There are two programs that make it easy to create the design
matrix, contrast and exchangeability-block files <code>design.mat / design.con / design.grp </code>. The
first is the <code>Glm</code> GUI which allows the specification of
designs in the same way as in FEAT, and the second is a simple script
to allow you to easily generate design files for the two-group
unpaired t-test case, called <code>design_ttest2</code>.

<p><b>randomise</b> has the following thresholding/output options:

<UL>

  <LI> Voxel-based thresholding, both uncorrected and corrected for
  multiple comparisons by using the null distribution of the max
  (across the image) voxelwise test statistic. Uncorrected outputs
  are: <code>&lt;output&gt;_vox_p_tstat</code> / <code>
  &lt;output&gt;_vox_p_fstat</code>. Corrected outputs
  are: <code>&lt;output&gt;_vox_corrp_tstat</code> / <code>
  &lt;output&gt;_vox_corrp_fstat</code>. To use this option, use
  <code>-x</code>.

  <p><LI> TFCE (Threshold-Free Cluster Enhancement) is a new method
  for finding "clusters" in your data without having to define
  clusters in a binary way. Cluster-like structures are enhanced but
  the image remains fundamentally voxelwise; you can use
  the <code>-tfce</code> option in <code>fslmaths</code> to test this
  on an existing stats image. See
  the <a href="http://www.fmrib.ox.ac.uk/analysis/research/tfce">TFCE
  research page</a> for more information. The "E", "H" and
  neighbourhood-connectivity parameters have been optimised and should
  be left unchanged. These optimisations are different for different
  "dimensionality" of your data; for normal, 3D data (such as in an
  FSL-VBM analysis), you should just just the <code>-T</code> option,
  while for TBSS analyses (that is in effect on the mostly "2D" white
  matter skeleton), you should use the <code>--T2</code> option.

  <p><LI> Cluster-based thresholding corrected for multiple
  comparisons by using the null distribution of the max (across the
  image) cluster size (so pass&#233;!): <code>&lt;output&gt;_clustere_corrp_tstat</code>
  / <code>&lt;output&gt;_clustere_corrp_fstat</code><br>To use this option,
  use <code>-c &lt;thresh&gt;</code> for t contrasts and <code>-F
  &lt;thresh&gt;</code> for F contrasts, where the threshold is used
  to form supra-threshold clusters of voxels.
  
  <p><LI> Cluster-based thresholding corrected for multiple comparisons
  by using the null distribution of the max (across the image) cluster
  <em>mass</em>: <code>&lt;output&gt;_clusterm_corrp_tstat</code> /
  <code>&lt;output&gt;_clusterm_corrp_fstat</code><br> To use this option,
  use <code>-C &lt;thresh&gt;</code> for t contrasts and
      <code>-S &lt;thresh&gt;</code> for F contrasts.

</UL>

These filename extensions are summarized in table below.

<p><center>
<table
  border="2"
  cellspacing="2">
<tr>
  <th rowspan="2" ></th>
  <th rowspan="2" align="center">Voxel-wise</th>
  <th rowspan="2" align="center">TFCE</th>
  <th colspan="2" align="center">Cluster-wise</th>
</tr>
<tr>
  <th align="center">Extent</th>
  <th align="center">Mass</th>
</tr>
<tr>
  <td align="left">Raw test statistic</td>
  <td align="center"><code>_tstat</code><BR><code>_fstat</code></td>
  <td align="center"><code>_tfce_tstat</code><BR><code>_tfce_fstat</code></td>
  <td align="center">n/a</td>
  <td align="center">n/a</td>
</tr>    
<tr>
  <td align="left">1 - Uncorrected P</td>
  <td align="center"><code>_vox_p_tstat</code><BR><code>_vox_p_fstat</code></td>
  <td align="center"><code>_tfce_p_tstat</code><BR><code>_tfce_p_fstat</code></td>
  <td align="center">n/a</td>
  <td align="center">n/a</td>
</tr>    
<tr>
  <td align="left"  >1 - FWE-Corrected P</td>
  <td align="center"><code>_vox_corrp_tstat</code><BR><code>_vox_corrp_fstat</code></td>
  <td align="center"><code>_tfce_corrp_tstat</code><BR><code>_tfce_corrp_fstat</code></td>
  <td align="center"><code>_clustere_corrp_tstat</code><BR><code>_clustere_corrp_fstat</code></td>
  <td align="center"><code>_clusterm_corrp_tstat_</code><BR><code>_clusterm_corrp_tstat_</code></td>
</tr>    
</table>
</center>

<p>&quot;FWE-corrected&quot; means that the family-wise error rate is
controlled. If only FWE-corrected P-values less than 0.05 are accepted,
the chance of one more false positives occurring over space space is
no more than 5%. Equivalently, one has 95% confidence of no false
positives in the image.

<p>Note that these output images are 1-P images, where a value of 1 is
therefore most significant (arranged this way to make display and
thresholding convenient). Thus to "threshold at p&lt;0.01", threshold
the output images at 0.99 etc.

<p>If your design is simply all 1s (for example, a single group of
subjects) then randomise needs to work in a different way. Normally it
generates random samples by randomly permuting the rows of the design;
however in this case it does so by randomly inverting the sign of the
1s. In this case, then, instead of specifying design and contrast
matrices on the command line, use the <code>-1</code> option.

<p>You can potentially improve the estimation of the variance that
feeds into the final "t" statistic image by using the variance
smoothing option <code>-v &lt;std&gt;</code> where you need to specify
the spatial extent of the smoothing in mm.

<a name="examples"></a><hr><h2>EXAMPLES</h2>

<p><b>One-Sample T-test.</b>

<p>To perform a nonparametric 1-sample t-test (e.g., on COPEs created
  by FEAT FMRI analysis), create a 4D image of all of the images.
  There should be no repeated measures, i.e., there should only be one
  image per subject. Because this is a single group simple design you
  don't need a design matrix or contrasts. Just use:<BR>

<code>randomise -i OneSamp4D -o OneSampT -1 -T</code><br>

Note you do not need the <code>-D</code> option (as the mean is in the
model), and omit the <code>-n</code> option, so that 5000 permutations
will be performed.

<P>If you have fewer than 20 subjects (approx. 20 DF), then you will
usually see an increase in power by using variance smoothing, as in

<BR><code>randomise -i OneSamp4D -o OneSampT -1 -v 5 -T</code><br>

which does a 5mm HWHM variance smoothing.  

<P>Note also that randomise will automatically select one-sample mode for 
appropriate design/contrast combinations.

<br><p><b>Two-Sample Unpaired T-test</b>

<p> To perform a nonparametric 2-sample t-test, create
4D image of all of the images, with the subjects in the right order!
Create appropriate <a href="design.mat">design.mat</a> and <a
href="design.con">design.con</a> files.

<P>Once you have your design files run:

<BR><code>
randomise -i TwoSamp4D -o TwoSampT -d design.mat -t design.con -m mask -T
</code><br>


<br><p><b>Two-Sample Unpaired T-test with nuisance variables.</b>

<p> To perform a nonparametric 2-sample t-test in the presence of
nuisance variables, create a 4D image of all of the images.  Create
appropriate <code>design.mat</code> and <code>design.con</code> files,
where your design matrix has additional nuisance variables that are
(appropriately) ignored by your contrast.

<P>Once you have your design files the call is as before:

<p><code>
randomise -i TwoSamp4D -o TwoSampT -d design.mat -t design.con -m mask -T
</code><br>


<a name="Ex:RepeatMeas"><br><p><b>Repeated measures ANOVA</b> 

<p>Following
the <a
href="../feat5/detail.html#ANOVA1factor4levelsRepeatedMeasures">ANOVA:
1-factor 4-levels (Repeated Measures)</a> example from the FEAT
manual, assume we have 2 subjects with 1 factor at 4 levels.  We
therefore have eight input images and we want to test if there is any
difference over the 4 levels of the factor.  The design matrix looks
like

<pre>
1 0 1 0 0
1 0 0 1 0
1 0 0 0 1
1 0 0 0 0
0 1 1 0 0
0 1 0 1 0
0 1 0 0 1
0 1 0 0 0
</pre>
where the first two columns model subject means and the 3rd through
5th column model the categorical effect (Note the different
arrangement of rows relative to the FEAT example).  Three t-contrasts 
for the categorical effect
<pre>
0 0 1 0 0
0 0 0 1 0
0 0 0 0 1
</pre>
are selected together into a single F-contrast
<pre>
1 1 1
</pre>


<P>Modify the exchangeability-block information in <code>design.grp</code> to match
<pre>
1
1
1
1
2
2
2
2
</pre> 
This will ensure that permutations will only occur within subject,
respecting the repeated measures structure of the data.

<P>The number of permutations can be computed for each group, and then
  multiplied together to find the total number of permutations.  We use
  the ANOVA computation for 4 levels, and hence (1+1+1+1)!/1!/1!/1!/1!
  = 24 possible permutations for one subject, and hence 24 &times; 24
  = 576 total permutations.

The call is then similar to the above examples:<br>
<code>randomise -i TwoSamp4D -o TwoSampT -d design.mat -t design.con 
-f design.fts -m mask -e design.grp -T</code><BR>


<a name="theory"></a><hr><H2>BACKGROUND THEORY</H2>


<P>A standard nonparametric test is exact, in that the false
positive rate is exactly equal to the specified &alpha; level.  Using
<b>randomise</b> with a GLM that corresponds to one of the following
simple statistical models will result in exact inference:

<ol>
  <li>One sample t-test on difference measures
  <li>Two sample t-test
  <li>One-way ANOVA
  <li>Simple correlation
</ol>

Use of almost any other GLM will result in <em>approximately</em> exact
inference.  In particular, when the model includes both the effect
tested (e.g., difference in FA between two groups) and nuisance
variables (e.g., age), exact tests are not generally available.
Permutation tests rely on an assumption of exchangeability; with the
models above, the null hypothesis implies complete exchangeability of
the observations.  When there are nuisance effects, however, the null
hypothesis no longer assures the exchangeability of the data
(e.g. even when the null hypothesis of no FA difference is true, age
effects imply that you can't permute the data without altering the
structure of the data).

<p><b>Permutation tests for the General Linear Model</b>

<P>For an arbitrary GLM <b>randomise</b> uses the method of
Freeman &amp; Lane (1983). Based on the contrast (or set of contrasts
defining an F 
test), the design matrix is automatically partitioned into tested
effects and nuisance (confound) effects. 
The data are first fit to the nuisance effects alone and
nuisance-only residuals are formed.  These residuals are permuted,
and then the estimated nuisance signal is added back on, 
creating
an (approximate) realization of data under the null hypothesis.  This
realization is fit to the full model and the desired test 
statistic is computed as usual.  This process is repeated to build a 
distribution of test statistics equivalent under the null hypothesis
specified by the contrast(s).  For the simple models above, this
method is equivalent to the standard exact tests; otherwise, it
accounts for nuisance variation present under the null.

<!-- Delete after release of  next version -->
Note, that randomise v2.0 and earlier used a method due to 
Kennedy (1995).  While both
the Freedman-Lane and Kennedy methods are accurate for large <i>n</i>,
for small <i>n</i> the Kennedy method can tend to false inflate
significances.  For a review of these issues and even more possible
methods, see  Anderson &amp; Robinson (2001)
<!-- ----------------------------------- -->

<!-- <P>(For computational efficiency, the method is actually implimented in -->
<!-- the following manner.  As an intitialization step, the -->
<!-- data and tested effects are orthogonalized w.r.t. the -->
<!-- nuisance effects. The othorgonalized data are permuted and then -->
<!-- orthoganalized again w.r.t. the nuisance effects.  This once-permuted, -->
<!-- twice-orthogonalized data is then regressed on the (orthogonalized) -->
<!-- effects to be tested, producing the same test statistic as would be -->
<!-- obtained above.) -->

<P>This approximate permutation test is asymptotically exact, meaning that
the results become more accurate with an ever-growing sample size
(for a fixed number of regressors).  For large sample sizes, with
50-100 or more degrees of freedom, the P-values should be highly
accurate.  When the sample size is low <em>and</em> there are many
nuisance regressors, accuracy could be a problem.  (The accuracy is
easily assessed by generating random noise data and fitting it to your
design; the uncorrected P-values should be uniformly spread between
zero and one; the test will be invalid if there is an excess of small
P-values and conservative if there is a deficit of small P-values.)

<p><b>Monte Carlo Permutation Tests</b>

<P>A proper "exact" test arises from evaluating every possible
permutation.  Often this is not feasible, e.g., a simple correlation
with 12 scans has nearly a half a billion possible permutations.
Instead, a random sample of possible permutations can be used,
creating a Monte Carlo permutation test.  On average the Monte Carlo
test is exact and will give similar results to carrying out all
possible permutations.

<P>If the number of possible permutations is
large, one can show that a true, exhaustive P-value of <em>p</em> will
produce Monte Carlo P-values between <em>p</em> &plusmn;
2&radic;(<em>p</em>(1-<em>p</em>)/<em>n</em>) about 95% of the time,
where <em>n</em> is the number of Monte Carlo permutations.  

The table below shows confidence limits for <em>p</em>=0.05 for various
<em>n</em>.  At least 5,000 permutations are required to reduce the
uncertainty appreciably, though 10,000 permutations are required to
reduce the margin-of-error to below 10% of the nominal alpha.

<center>
<table
  border="0"
  cellspacing="10">
<tr>
<th><em>n</em></th>
<th>Confidence limits<BR>for <em>p</em>=0.05</th>
</tr>
<tr>
<td align="right">100</td>
<td>0.0500 &plusmn; 0.0436</td>
</tr>
<tr>
<td align="right">1,000</td>
<td>0.0500 &plusmn; 0.0138</td>
</tr>
<tr>
<td align="right">5,000</td>
<td>0.0500 &plusmn; 0.0062</td>
</tr>
<tr>
<td align="right">10,000</td>
<td>0.0500 &plusmn; 0.0044</td>
</tr>
<tr>
<td align="right">50,000</td>
<td>0.0500 &plusmn; 0.0019</td>
</table>
</center>

In <b>randomise</b> the number of permutations to use is specified
with the <code>-n</code> option.  If this number is greater than or equal
to the number of possible permutations, an exhaustive test is run.  If
it is less than the number of possible permutations a Monte Carlo
permutation test is performed.  The default is 5000, though if time
permits, 10000 is recommended.



<p><b>Counting Permutations</b> 

<p>Exchangeabilty under the null hypothesis justifies the permutation
of the data.  For n scans, there are n! (n factorial,
n&times;(n-1)&times;(n-2)&times;...&times;2) possible ways of
shuffling the data.  For some designs, though, many of these shuffles
are redundant.  For example, in a two-sample t-test, permuting two
scans within a group will not change the value of the test statistic.
The number of possible permutations for different designs are given
below.

<center>
<table 
  border="0"
  cellspacing="10">
<tr>
<th>Model</th>
<th>Sample Size(s)</th>
<th>Number of Permutations</th>
</tr>
<tr>
  <td>One sample t-test on<BR>difference measures</td> 
  <td>n</td>     
  <td>2<sup>n</sup></td>
</tr>

<tr>
   <td>Two sample t-test</td>
   <td>n<sub>1</sub>,n<sub>2</sub></td> 
   <td>(n<sub>1</sub>+n<sub>2</sub>)! &nbsp; / &nbsp; ( n<sub>1</sub>! &times;
   n<sub>2</sub>! )</td>
</tr>
<tr>
   <td>One-way ANOVA</td>
   <td>n<sub>1</sub>,...,n<sub>k</sub></td>
   <td>(n<sub>1</sub>+n<sub>2</sub>+ ... + n<sub>k</sub>)!
     &nbsp; / &nbsp; 
     ( n<sub>1</sub>! &times; n<sub>2</sub>! &times; ... &times; n<sub>k</sub>! )</td>
</tr>

<tr>
  <td>Simple correlation</td> 
  <td>n</td>
  <td>n!</td>
</tr>      
</table>
</center>

Note that the one-sample t-test is an exception.  Data are not
permuted, but rather their signs are randomly flipped.  For all designs except a one-sample
t-test, <b>randomise</b> uses a generic algorithm which counts
the number of unique possible permutations for each contrast.  If
<em>X</em> is the design matrix and <em>c</em> is the 
contrast of interest, then <em>Xc</em> is sub-design matrix of the
effect of interest.  The number of unique rows in  <em>Xc</em> is
counted and a one-way ANOVA calculation is used.

<p><b>Parallelising Randomise</b> 

<p>If you are have an SGE-capable system then a randomise job can be split in parallel with <code>randomise_parallel</code> which takes
the same input options as the standard randomise binary and then calculates and batches an optimal number of randomise sub-tasks. The parallelisation has two stages - firstly the randomise sub-jobs are run, and then the sub-job results are combined in the final output.


<a name="refs"></a><hr><p><h2>REFERENCES</h2>

<P>MJ Anderson &amp; J Robinson.  
Permutation Tests for Linear Models.
<em>Aust. N.Z. J. Stat.</em> 43(1):75-88, 2001.


<P>Bullmore, ET and Suckling, J and Overmeyer, S and
                  Rabe-Hesketh, S and Taylor, E and Brammer, MJ
Global, voxel, and cluster tests, by theory and
                  permutation, for a difference between two groups of
                  structural MR images of the brain.
<em>IEEE TMI</em>, 18(1):32-42, 1999.

<P>D Freedman &amp; D Lane.
A nonstocastic interpretation of reported significance levels.   
<em>J. Bus. Econom. Statist.</em> 1:292-298, 1983. 

<P>S Hayasaka &amp; TE Nichols.
Validating cluster size inference: random field and permutation methods.
<em>NeuroImage</em>, 20:2343-2356, 2003

<P>PE Kennedy.  
Randomization tests in econometrics.
<em>J. Bus. Econom. Statist.</em> 13:84-95, 1995.

<P>TE Nichols and AP Holmes. 
Nonparametric Permutation Tests for Functional Neuroimaging: A
Primer with Examples.
<em>Human Brain Mapping</em>, 15:1-25, 2002.




<p><HR><FONT SIZE=1>Copyright &copy; 2004-2007, University of
Oxford. Written by T. Behrens, S. Smith, M. Webster and
T. Nichols.</FONT>

<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>
<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>
<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>
<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>

</BODY></HTML>

